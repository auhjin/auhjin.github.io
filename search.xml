<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Linux 搭建离线yum源</title>
      <link href="/2024/01/15/%E6%90%AD%E5%BB%BA%E7%A6%BB%E7%BA%BFyum%E6%BA%90/"/>
      <url>/2024/01/15/%E6%90%AD%E5%BB%BA%E7%A6%BB%E7%BA%BFyum%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<p>工作中，虚拟机通常都是部署在内网环境中，无法连接互联网，因此无法使用互联网上的YUM源。<br>经常会遇到系统ISO镜像中软件包缺失，系统软件补丁无法升级，第三方软件包无法安装等情况。</p><p>本文通过搭建离线YUM源，解决了上述问题。</p><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p>准备一台可以联网的linux机器<br>安装创建YUM仓库的软件工具</p><pre><code class="shell">[root@localhost yum.repos.d]# yum install createrepo yum-utils -y</code></pre><p>![[Pasted image 20230630202201.png]]<br>移除初始的其他镜像源</p><pre><code class="shell">[root@localhost ~]# cd /etc/yum.repos.d/  [root@localhost yum.repos.d]# mkdir bak  [root@localhost yum.repos.d]# mv * bak</code></pre><p>![[Pasted image 20230630202240.png]]<br>下载阿里云的repo文件</p><pre><code class="bash">[root@localhost ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo[root@localhost ~]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo</code></pre><pre><code>什么是yum源repo文件，repo文件是yum源（软件仓库）的配置文件，通常一个repo文件定义了一个或者多个软件仓库的配置内容，例如将从哪里下载需要安装或者升级的软件包，repo文件中的设置内容将被yum读取和应用。</code></pre><p>![[Pasted image 20230630203607.png]]<br>![[Pasted image 20230630202353.png]]<br>构建YUM源缓存</p><pre><code class="shell">[root@localhost ~]# yum clean all   #清除当前的yum源缓存(base) [root@localhost yum.repos.d]# yum install -y epel-release[root@localhost ~]#  yum makecache  #重新生成缓存[root@localhost ~]#  yum repolist   #查看当前可用的YUM源</code></pre><p>![[Pasted image 20230630202516.png]]<br>![[Pasted image 20230630205239.png]]<br>安装并启用httpd服务</p><pre><code class="shell">[root@localhost /]# yum install httpd[root@localhost /]# systemctl start httpd[root@localhost /]# systemctl status httpd● httpd.service - The Apache HTTP ServerLoaded: loaded (/usr/lib/systemd/system/httpd.service; disabled; vendor preset: disabled)Active: active (running) since Wed 2021-06-30 00:49:06 CST; 5s ago....output omitted....</code></pre><p>![[Pasted image 20230630203747.png]]<br>![[Pasted image 20230630203826.png]]</p><h4 id="同步阿里云的YUM源到本地"><a href="#同步阿里云的YUM源到本地" class="headerlink" title="同步阿里云的YUM源到本地"></a>同步阿里云的YUM源到本地</h4><pre><code class="shell"> #reposync根据之前下载的repo文件下载rpm包到指定文件夹,  #这个服务器home文件夹下的空间比较多，同步下载到 /home路径下，mkdir /phm/yum[root@localhost /]# cd /home/phm/yum[root@localhost yum]# reposync -r base [root@localhost yum]# reposync -r extras[root@localhost yum]# reposync -r updates[root@localhost yum]# reposync -r epel</code></pre><p>![[Pasted image 20230701115938.png]]<br>![[Pasted image 20230701120738.png]]</p><h4 id="创建本地YUM仓库"><a href="#创建本地YUM仓库" class="headerlink" title="创建本地YUM仓库"></a>创建本地YUM仓库</h4><pre><code class="shell"># 为本地yum仓库，生成新的repo文件[root@localhost yum]# cd /home/phm/yum/base[root@localhost yum]# createrepo ./[root@localhost yum]# cd /home/phm/yum/extras[root@localhost yum]# createrepo ./[root@localhost yum]# cd /home/phm/yum/updates[root@localhost yum]# createrepo ./[root@localhost yum]# cd /home/phm/yum/epel[root@localhost yum]# createrepo ./</code></pre><p>![[Pasted image 20230702202732.png]]<br>![[Pasted image 20230702202807.png]]</p><h4 id="更新YUM仓库"><a href="#更新YUM仓库" class="headerlink" title="更新YUM仓库"></a>更新YUM仓库</h4><p>到此本地YUM仓库搭建完成，<strong>如果在对应的仓库中加入新的软件包时</strong>，需要更新仓库。本文中不涉及。</p><pre><code class="shell">[root@localhost ]#  createrepo --update /var/www/html/yum/epel</code></pre><h4 id="离线YUM仓库的使用"><a href="#离线YUM仓库的使用" class="headerlink" title="离线YUM仓库的使用"></a>离线YUM仓库的使用</h4><p>将本机&#x2F;var&#x2F;www&#x2F;html&#x2F;yum目录通过sftp等客户端工具保存到移动硬盘，之后再上传到现有的yum源主机对应目录中。更新客户端主机的yum源配置，指向新的YUM仓库目录，即可正常使用该YUM仓库。配置维护域ip地址，确保与其他主机网络正常通信。配置客户端主机的yum源配置文件，将YUM仓库指向该主机，即可正常使用该YUM仓库。客户端yum源配置文件如下：</p><pre><code># 3种文件获取方式# 1. HTTPbaseurl=http://10.16.9.34/yum/base# 2. 本地文件获取baseurl=file:///home/yum/base# 3. FTPbaseurl=ftp://10.16.9.34/yum/base</code></pre><pre><code class="shell">[root@client yum.repos.d]# cd /etc/yum.repos.d[root@client yum.repos.d]# mkdir bak ; mv * bak[root@client yum.repos.d]# vi http.repo[base]name=RHEL- - Base - httpbaseurl=http://10.16.9.34/centos/yum/baseenabled=1gpgcheck=0[updates]name=RHEL- - updates - httpbaseurl=http://10.16.9.34/centos/yum/updatesenabled=1gpgcheck=0[epel]name=RHEL- - epel - httpbaseurl=http://10.16.9.34/centos/yum/epelenabled=1gpgcheck=0[extras]name=RHEL- - extras - httpbaseurl=http://10.16.9.34/centos/yum/extrasenabled=1gpgcheck=0[root@client yum.repos.d]# yum clean all[root@client yum.repos.d]# yum makecache[root@client yum.repos.d]# yum list | grep kernelkernel.x86_64                            3.10.0-1160.el7               @anacondakernel-tools.x86_64                      3.10.0-1160.el7               @anacondaabrt-addon-kerneloops.x86_64             2.1.11-60.el7.centos          basekernel-debug-devel.x86_64                3.10.0-1160.31.1.el7          updateskernel-devel.x86_64                      3.10.0-1160.31.1.el7          updates[root@client yum.repos.d]# yum install kernelLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfileResolving Dependencies--&gt; Running transaction check---&gt; Package kernel.x86_64 0:3.10.0-1160.31.1.el7 will be installed--&gt; Finished Dependency Resolution.....output ommitted.........Transaction test succeededRunning transaction  Installing : kernel-3.10.0-1160.31.1.el7.x86_64                                       Complete!客户端测试安装kernel软件包，成功安装。</code></pre><p>![[Pasted image 20230712131018.png]]</p><h3 id="超融合主机磁盘I-O"><a href="#超融合主机磁盘I-O" class="headerlink" title="超融合主机磁盘I&#x2F;O"></a>超融合主机磁盘I&#x2F;O</h3><p>60G 的yum文件，从9:20 – 12:55<br>![[Pasted image 20230712131354.png]]</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 调整根目录和home目录的空间大小</title>
      <link href="/2024/01/15/Linux%E4%B8%8B%E8%B0%83%E6%95%B4%E6%A0%B9%E7%9B%AE%E5%BD%95%E5%92%8Chome%E7%9B%AE%E5%BD%95%E7%9A%84%E7%A9%BA%E9%97%B4%E5%A4%A7%E5%B0%8F/"/>
      <url>/2024/01/15/Linux%E4%B8%8B%E8%B0%83%E6%95%B4%E6%A0%B9%E7%9B%AE%E5%BD%95%E5%92%8Chome%E7%9B%AE%E5%BD%95%E7%9A%84%E7%A9%BA%E9%97%B4%E5%A4%A7%E5%B0%8F/</url>
      
        <content type="html"><![CDATA[<p>当安装完 Linux 操作系统，发现磁盘分区大小错误，或者后期使用过程发现 &#x2F;home 还剩余很多空间，&#x2F; 下空间不足，需要将 &#x2F;home 下空间重新分配给 &#x2F;目录下<br>1、查看分区空间和格式</p><pre><code>root@mongodb~# df -hT  文件系统 类型 容量 已用 可用 已用% 挂载点  /dev/mapper/centos-root xfs 50G 49G 1.4G 98% /  devtmpfs devtmpfs 5.8G 0 5.8G 0% /dev  tmpfs tmpfs 5.8G 0 5.8G 0% /dev/shm  tmpfs tmpfs 5.8G 602M 5.3G 11% /run  tmpfs tmpfs 5.8G 0 5.8G 0% /sys/fs/cgroup  /dev/sda1 xfs 1014M 153M 862M 16% /boot  /dev/mapper/centos-home xfs 44G 36M 44G 1% /home  tmpfs tmpfs 1.2G 0 1.2G 0% /run/user/0</code></pre><p>这里要将 &#x2F;home 的空闲空间分给 &#x2F; 目录一部分</p><p>可以看到 &#x2F;home 分区是 xfs 格式</p><p>1）ext2&#x2F;ext3&#x2F;ext4文件系统的调整命令是resize2fs（增大和减小都支持）</p><pre><code>lvextend -L 120G /dev/mapper/centos-home //增大至120G  lvextend -L +20G /dev/mapper/centos-home //增加20G  lvreduce -L 50G /dev/mapper/centos-home //减小至50G  lvreduce -L -8G /dev/mapper/centos-home //减小8G  resize2fs /dev/mapper/centos-home //执行调整</code></pre><p>2）xfs文件系统的调整命令是xfs_growfs（只支持增大）</p><pre><code>lvextend -L 120G /dev/mapper/centos-home //增大至120G  lvextend -L +20G /dev/mapper/centos-home //增加20G  xfs_growfs /dev/mapper/centos-home //执行调整</code></pre><p>xfs文件系统只支持增大分区空间的情况，不支持减小的情况。</p><p>硬要减小的话，只能在减小后将逻辑分区重新通过 mkfs.xfs 命令重新格式化才能挂载上，这样的话这个逻辑分区上原来的数据就丢失了。如果有重要文件，禁用或移除文件</p><p>2、卸载 &#x2F;home 分区</p><pre><code>[root@mongodb-1 /]# umount /home[root@mongodb-1 /]#   文件系统 容量 已用 可用 已用% 挂载点  /dev/mapper/centos-root 50G 49G 1.4G 98% /  devtmpfs 5.8G 0 5.8G 0% /dev  tmpfs 5.8G 0 5.8G 0% /dev/shm  tmpfs 5.8G 602M 5.3G 11% /run  tmpfs 5.8G 0 5.8G 0% /sys/fs/cgroup  /dev/sda1 1014M 153M 862M 16% /boot  tmpfs 1.2G 0 1.2G 0% /run/user/0</code></pre><p>卸载成功<br>3、将 &#x2F;home 分区减小200G（根据自己实际情况设定大小） ：</p><pre><code>[root@mongodb-1 /]# lvreduce -L -40G /dev/mapper/centos-home  WARNING: Reducing active logical volume to &lt; 3.12 GiB.  THIS MAY DESTROY YOUR DATA (filesystem etc.)  Do you really want to reduce centos/home? [y/n]: y  Size of logical volume centos/home changed from &lt;43.12 GiB (11038 extents) to &lt; 3.12 GiB (798 extents).  Logical volume centos/home successfully resized.</code></pre><p>因为 xfs文件系统不能执行分区减小的调整！所以这里我们要执行格式化操作，</p><pre><code>[root@mongodb-1 /]# mkfs.xfs /dev/mapper/centos-home -f  meta-data=/dev/mapper/centos-home isize=512 agcount=4, agsize=204288 blks  = sectsz=512 attr=2, projid32bit=1  = crc=1 finobt=0, sparse=0  data = bsize=4096 blocks=817152, imaxpct=25  = sunit=0 swidth=0 blks  naming =version 2 bsize=4096 ascii-ci=0 ftype=1  log =internal log bsize=4096 blocks=2560, version=2  = sectsz=512 sunit=0 blks, lazy-count=1  realtime =none extsz=4096 blocks=0, rtextents=0</code></pre><p>重新挂载 &#x2F;home 分区：</p><pre><code>mount /dev/mapper/centos-home /home/</code></pre><p>5、将上面空余的 200G 分到 &#x2F; 分区下</p><pre><code>[root@mongodb-1 /]# lvextend -L +40G /dev/mapper/centos-root  Size of logical volume centos/root changed from 50.00 GiB (12800 extents) to 90.00 GiB (23040 extents).  Logical volume centos/root successfully resized.  [root@mongodb-1 /]# xfs_growfs /dev/mapper/centos-root  meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=3276800 blks  = sectsz=512 attr=2, projid32bit=1  = crc=1 finobt=0 spinodes=0  data = bsize=4096 blocks=13107200, imaxpct=25  = sunit=0 swidth=0 blks  naming =version 2 bsize=4096 ascii-ci=0 ftype=1  log =internal bsize=4096 blocks=6400, version=2  = sectsz=512 sunit=0 blks, lazy-count=1  realtime =none extsz=4096 blocks=0, rtextents=0  data blocks changed from 13107200 to 23592960</code></pre><pre><code>[root@mongodb-1 /]# df -h  文件系统 容量 已用 可用 已用% 挂载点  /dev/mapper/centos-root 90G 49G 42G 55% /  devtmpfs 5.8G 0 5.8G 0% /dev  tmpfs 5.8G 0 5.8G 0% /dev/shm  tmpfs 5.8G 602M 5.3G 11% /run  tmpfs 5.8G 0 5.8G 0% /sys/fs/cgroup  /dev/sda1 1014M 153M 862M 16% /boot  tmpfs 1.2G 0 1.2G 0% /run/user/0  /dev/mapper/centos-home 3.2G 33M 3.1G 2% /home</code></pre>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python环境离线安装</title>
      <link href="/2024/01/10/Python%20%E7%8E%AF%E5%A2%83%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/"/>
      <url>/2024/01/10/Python%20%E7%8E%AF%E5%A2%83%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h1 id="pip-通过-requirements-文件，批量下载python包，批量离线安装python包"><a href="#pip-通过-requirements-文件，批量下载python包，批量离线安装python包" class="headerlink" title="pip 通过 requirements 文件，批量下载python包，批量离线安装python包"></a>pip 通过 requirements 文件，批量下载python包，批量离线安装python包</h1><h4 id="1、首先，在开发项目环境中分析出所有依赖的库"><a href="#1、首先，在开发项目环境中分析出所有依赖的库" class="headerlink" title="1、首先，在开发项目环境中分析出所有依赖的库"></a>1、首先，在开发项目环境中分析出所有依赖的库</h4><pre><code class="shell">pip freeze &gt; requirements.txt # 该方法仅可以使用在虚拟环境中，会将python 解释器下的所有包都导出pipreqs ./ --encoding=utf-8 --force # 表示覆盖该原有requirements.txt</code></pre><h4 id="2-在有网络的目标环境中，将所有包下载到DIR这个目录中"><a href="#2-在有网络的目标环境中，将所有包下载到DIR这个目录中" class="headerlink" title="2. 在有网络的目标环境中，将所有包下载到DIR这个目录中"></a>2. 在有网络的目标环境中，将所有包下载到DIR这个目录中</h4><p>切记，不要在 windows 下载包，然后放到 Linux 上进行安装，这样基本装不上</p><pre><code class="shell">pip download -d DIR -r requirements.txtpip wheel -w DIR -r requirements.txt</code></pre><ul><li>这两条命令的区别在于wheel 方式下载会将下载的包放入wheel 缓存，但缺点是wheel 不可以下载源码包</li><li>download 命令会查看wheel缓存，然后再去PyPI下载库，但download命令下载的包不会进入wheel缓存，download 的优点是可以下载源码包</li><li>需要注意，使用wheel 方式安装可能会报错，因为有些包是源码包，不能被打包成wheel 格式</li><li>download 方法下载的包，不会对依赖性进行检查，这意味着，如果下载 Flask-PyMongo 这个包，只会下载该包，而不会下载 pymongo，经试验发现，download 适合补充wheel不可下载的包，两者搭配使用，才能将requirements文件的库完整的下载</li></ul><h4 id="3-将文件打包后放到离线服务器上，并进行解压缩"><a href="#3-将文件打包后放到离线服务器上，并进行解压缩" class="headerlink" title="3. 将文件打包后放到离线服务器上，并进行解压缩"></a>3. 将文件打包后放到离线服务器上，并进行解压缩</h4><pre><code>pip install --no-index --find-links=DIR -r requirements.txt</code></pre><p>命令说明</p><ul><li>freeze 将依赖关系分析出来并 使用管道符导入到该文件中</li><li>download 分析 requirements 文件，将所有包进行下载，通过 d 选项导入 DIR 文件夹</li><li>wheel 分析requirements 文件，并将所有包及其依赖包下载为 wheel 格式，通过 w 选项导入 DIR 文件夹中</li><li>–find-links 指定离线安装的文件夹DIR，也就是你下载好的包</li><li>注意: –no-index 必须搭配 –find-links 使用</li></ul><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><ol><li>安装时报错，不能找到相应的包，打开文件夹后却发现有这个库<ol><li>原因可能是该库是3.10 版本，而服务器是3.9 版本，导致安装不上</li><li>使用以下命令选择合适的版本，注意 <code>--no-deps</code> 不可缺少，</li></ol><pre><code>pip download  --no-deps--platform linux_x86_64--python-version 36--implementation cp  --abi cp36m     -r requirements.txt -d pk</code></pre></li></ol><pre><code></code></pre>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 本地部署Hadoop、Spark、Zookeeper、Hive集群</title>
      <link href="/2024/01/08/Docker%20%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Hadoop%EF%BC%8CSpark%EF%BC%8CZookeeper%EF%BC%8CHive%E9%9B%86%E7%BE%A4/"/>
      <url>/2024/01/08/Docker%20%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Hadoop%EF%BC%8CSpark%EF%BC%8CZookeeper%EF%BC%8CHive%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql、Redis、Tdengine-省略…-直接docker容器拉取"><a href="#Mysql、Redis、Tdengine-省略…-直接docker容器拉取" class="headerlink" title="Mysql、Redis、Tdengine 省略… 直接docker容器拉取"></a>Mysql、Redis、Tdengine 省略… 直接docker容器拉取</h2><h2 id="拉取各节点centos系统镜像"><a href="#拉取各节点centos系统镜像" class="headerlink" title="拉取各节点centos系统镜像"></a>拉取各节点centos系统镜像</h2><pre><code class="shell">## 设置docker网桥，用于分配固定IPdocker network create --subnet=172.15.0.0/16 netgroupdocker  pull  centosdocker run -d --privileged -ti -v D:\WorkStation\Bigdatadevelop\BigdataTools\master:/opt --name cluster-master -h cluster-master --net netgroup --ip 172.15.0.2 centos:centos7 /usr/sbin/initdocker run -d --privileged -ti -v D:\WorkStation\Bigdatadevelop\BigdataTools\slave1:/opt --name cluster-slave1-h cluster-slave1--net netgroup --ip 172.15.0.3 centos:centos7 /usr/sbin/init docker exec -ti 946556c3ae6c /bin/bash#改hostnamevi /etc/hostsservice network restart# 改yum源mkdir bakmv * bakmv Centos-7.repo /etc/yum.repos.d/mv epel-7.repo /etc/yum.repos.d/yum clean allyum makecacheyum repolistyum install httpdyum install net-toolsyum -y install openssh-clientsyum install openssh-server#免密配置systemctl status sshdpasswd rootssh-keygen -t rsassh-copy-id  -f -i ~/.ssh/id_rsa.pub cluster-masterssh-copy-id  -f -i ~/.ssh/id_rsa.pub cluster-slave1ssh-copy-id  -f -i ~/.ssh/id_rsa.pub cluster-slave2ssh-copy-id  -f -i ~/.ssh/id_rsa.pub cluster-slave3Pzszh@062# 容器保存成镜像docker commit -m &#39;提交文字说明&#39; -a &#39;作者&#39; 容器名 提交后的镜像名:提交后的镜像tag名# 给需要推送的镜像打标签docker tag 镜像id 要推入的仓库的用户名/要推入的仓库名:新定义的tag# 推送镜像到仓库docker push 要推入的仓库的用户名/要推入的仓库名:镜像标签</code></pre><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><pre><code class="shell">cd /opttar -xzvf zookeeper-3.4.10.tar.gzmv zookeeper-3.4.10 /usr/local/zookeeper3.4.10 mkdir /usr/local/opt/zookeeper3.4.10/data        # 创建data目录mkdir /usr/local/opt/zookeeper3.4.10/dataLog     # 创建dataLog目录cd /opt/zookeeper3.4.10/datavi myid     # 输入数字1，然后保存，第二个节点输入2，第三个节点输入3 cd /opt/zookeeper3.4.10/confcp zoo_sample.cfg zoo.cfgvi zoo.cfg             #在文件末尾添加如下内容dataDir=/opt/zookeeper3.4.10/data  dataLogDir=/opt/zookeeper3.4.10/dataLog  server.1=hadoop0:2888:3888  server.2=hadoop1:2888:3888  server.3=hadoop2:2888:3888  # 注hadoop0，hadoop1，hadoop2为三个节点的主机名！cd /usr/localscp -r zookeeper3.4.10  root@hadoop1:/usr/localscp -r zookeeper3.4.10  root@hadoop2:/usr/local分别在三台服务器上运行如下命令zkServer.sh start</code></pre><h3 id="添加-Hadoop-用户"><a href="#添加-Hadoop-用户" class="headerlink" title="添加 Hadoop 用户"></a>添加 Hadoop 用户</h3><pre><code class="shell">useradd -m hadoop -s /bin/bashpasswd hadoop# 添加 root权限vi /etc/passwd # hadoop:X:0:1000::/home/hadoop:/bin/bashsu - hadoop</code></pre><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><pre><code class="shell">tar -zxf hadoop-3.1.3.tar.gz -C /usr/local/cd /usr/local/mv ./hadoop-3.1.3/ ./hadoopchown -R hadoop ./hadoopvi ~/.bashrcexport PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin</code></pre><p>在配置集群&#x2F;分布式模式时，需要修改“&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;etc&#x2F;hadoop”目录下的配置文件，这里仅设置正常启动所必须的设置项，包括workers 、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml共5个文件，更多设置项可查看官方说明。</p><pre><code>## workers需要把所有数据节点的主机名写入该文件，每行一个，默认为 localhost（即把本机作为数据节点），在进行分布式配置时，可以保留localhost，让Master节点同时充当名称节点和数据节点，或者也可以删掉localhost这行，让Master节点仅作为名称节点使用。localhostcluster-mastercluster-slave1cluster-slave2</code></pre><pre><code class="xml"># core-site.xml&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;fs.defaultFS&lt;/name&gt;                &lt;value&gt;hdfs://cluster-master:9000&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;                &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;        &lt;/property&gt;&lt;/configuration&gt;</code></pre><pre><code class="xml">## hdfs-site.xml&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;                &lt;value&gt;cluster-master:50090&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;dfs.replication&lt;/name&gt;                &lt;value&gt;13/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;</code></pre><pre><code class="xml">## mapred-site.xml&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;                &lt;value&gt;yarn&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;                &lt;value&gt;cluster-master:10020&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;                &lt;value&gt;cluster-master:19888&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;                &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.map.env&lt;/name&gt;                &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;                &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;        &lt;/property&gt; &lt;/configuration&gt;</code></pre><pre><code class="xml">## yarn-site.xml&lt;configuration&gt;        &lt;property&gt;                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;                &lt;value&gt;cluster-master&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;        &lt;/property&gt;&lt;/configuration&gt;</code></pre><pre><code class="shell"># mastercd /usr/localrm -r ./hadoop/tmp # 删除 Hadoop 临时文件rm -r ./hadoop/logs/* # 删除日志文件tar -zcf ~/hadoop.master.tar.gz ./hadoop # 先压缩再复制cd ~scp ./hadoop.master.tar.gz Slave1:/home/hadoop</code></pre><pre><code class="shell"># slaverm -r /usr/local/hadoop # 删掉旧的（如果存在）tar -zxf ~/hadoop.master.tar.gz -C /usr/localchown -R hadoop /usr/local/hadoop</code></pre><pre><code># 切换 hadoop用户# 首次启动Hadoop集群时，需要先在Master节点执行名称节点的格式化（只需要执行这一次，后面再启动Hadoop时，不要再次格式化名称节点），命令如下：hdfs namenode -format# 启动Hadoop，启动需要在Master节点上进行，执行如下命令：start-dfs.shstart-yarn.sh mr-jobhistory-daemon.sh start historyserver</code></pre><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><pre><code class="shell">tar -zxf ~/下载/spark-2.4.0-bin-without-hadoop.tgz -C /usr/local/mv ./spark-2.4.0-bin-without-hadoop/ ./sparkchown -R hadoop:hadoop ./sparkcd /usr/local/sparkcp ./conf/spark-env.sh.template ./conf/spark-env.shvi ./conf/spark-env.shexport SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)</code></pre><pre><code>SPARK_LOCAL_DIRS=/usr/local/spark/HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoopYARN_CONF_DIR=//usr/local/hadoop/etc/hadoopJAVA_HOME=/usr/local/java/jdk1.8.0_162export SPARK_MASTER_IP=cluster-masterexport SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER-Dspark.deploy.zookeeper.url=172.15.0.2:2181-Dspark.deploy.zookeeper.dir=/sparkmaster&quot;</code></pre><h3 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h3><pre><code>cluster-slave1 cluster-slave2</code></pre><h3 id="spark-default-conf"><a href="#spark-default-conf" class="headerlink" title="spark-default.conf"></a>spark-default.conf</h3><pre><code>spark.eventLog.enabled          truespark.eventLog.dir              hdfs://jinbill/spark/eventLogspark.history.fs.logDirectory   hdfs://jinbill/spark/eventLogspark.eventLog.compress         true</code></pre><h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><pre><code class="shell">tar -zxvf apache-hive-3.1.2-bin.tar.gzmv apache-hive-3.1.2-bin /usr/local/hive# 新建一个日志目录mkdir /usr/local/hive/iotmp</code></pre><h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><pre><code class="shell">vi ~/.bashrcexport HIVE_HOME=/usr/local/hiveexport PATH=$HIVE_HOME/bin:$PATHsource ~/.bashrc</code></pre><h3 id="设置Hive-HDFS文件夹"><a href="#设置Hive-HDFS文件夹" class="headerlink" title="设置Hive HDFS文件夹"></a>设置Hive HDFS文件夹</h3><h3 id="解决guava库问题"><a href="#解决guava库问题" class="headerlink" title="解决guava库问题"></a>解决guava库问题</h3><pre><code class="shell"># 查看hadoop下guava 版本cd /usr/local/hadoop/share/hadoop/common/lib/# guava-27.0-jre.jar# 查看hive下guava 版本cd /usr/local/hive/lib# guava-19.0.jar# 高版本替换低版本</code></pre><h3 id="MySQL-中-建立hive数据库"><a href="#MySQL-中-建立hive数据库" class="headerlink" title="MySQL 中 建立hive数据库"></a>MySQL 中 建立hive数据库</h3><pre><code class="sql">CREATE DATABASE hive;</code></pre><h3 id="jdbc依赖导入"><a href="#jdbc依赖导入" class="headerlink" title="jdbc依赖导入"></a>jdbc依赖导入</h3><h4 id="将hive的jline包替换到hadoop的yarn下"><a href="#将hive的jline包替换到hadoop的yarn下" class="headerlink" title="将hive的jline包替换到hadoop的yarn下"></a>将hive的jline包替换到hadoop的yarn下</h4><pre><code class="shell">`mv /opt/hive/apache-hive-3.1.2-bin/lib/jline-2.12.jar /opt/hadoop/hadoop-2.7.7/share/hadoop/yarn/`# JDBC 依赖放入 /usr/local/hive/libmv mysql-connector-java-5.1.47.jar /usr/local/hive/lib/</code></pre><h3 id="修改master节点配置文件"><a href="#修改master节点配置文件" class="headerlink" title="修改master节点配置文件"></a>修改master节点配置文件</h3><pre><code>#### VI编辑器替换命令:%s/$&#123;system:java.io.tmpdir&#125;/\/opt\/hive\/iotmp/g  :%s/$&#123;system:user.name&#125;/huan/g</code></pre><h4 id="使用mysql替换默认的derby存放元数据"><a href="#使用mysql替换默认的derby存放元数据" class="headerlink" title="使用mysql替换默认的derby存放元数据"></a>使用mysql替换默认的derby存放元数据</h4><pre><code class="xml">&lt;!--元数据库修改为MySQL--&gt;&lt;property&gt;    &lt;name&gt;hive.metastore.db.type&lt;/name&gt;    &lt;value&gt;mysql&lt;/value&gt;    &lt;description&gt;      Expects one of [derby, oracle, mysql, mssql, postgres].      Type of database used by the metastore. Information schema &amp;amp; JDBCStorageHandler depend on it.    &lt;/description&gt;&lt;/property&gt;&lt;!--MySQL 驱动--&gt;&lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;!--MySQL URL--&gt;&lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;    &lt;value&gt;jdbc:mysql://10.20.89.80:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;    &lt;description&gt;      JDBC connect string for a JDBC metastore.      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.    &lt;/description&gt;&lt;/property&gt;&lt;!--MySQL 用户名--&gt;&lt;property&gt;  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;  &lt;value&gt;root&lt;/value&gt;  &lt;description&gt;Username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;!--MySQL 密码--&gt;&lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;    &lt;value&gt;123456&lt;/value&gt;    &lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;</code></pre><h4 id="设置解析引擎为spark"><a href="#设置解析引擎为spark" class="headerlink" title="设置解析引擎为spark"></a>设置解析引擎为spark</h4><pre><code class="xml">&lt;property&gt;    &lt;name&gt;hive.execution.engine&lt;/name&gt;    &lt;value&gt;spark&lt;/value&gt;    &lt;description&gt;      Expects one of [mr, tez, spark].      Chooses execution engine. Options are: mr (Map reduce, default), tez, spark. While MR      remains the default engine for historical reasons, it is itself a historical engine      and is deprecated in Hive 2 line. It may be removed without further warning.    &lt;/description&gt;&lt;/property&gt;</code></pre><h4 id="自动初始化元数据"><a href="#自动初始化元数据" class="headerlink" title="自动初始化元数据"></a>自动初始化元数据</h4><pre><code class="xml">&lt;property&gt;    &lt;name&gt;datanucleus.schema.autoCreateAll&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;    &lt;description&gt;Auto creates necessary schema on a startup if one doesn&#39;t exist. Set this to false, after creating it once.To enable auto create also set hive.metastore.schema.verification=false. Auto creation is not recommended for production use cases, run schematool command instead.    &lt;/description&gt;&lt;/property&gt;</code></pre><h4 id="关闭校验"><a href="#关闭校验" class="headerlink" title="关闭校验"></a>关闭校验</h4><pre><code class="xml">&lt;!--听说是JDK版本使用1.8的问题。。--&gt;&lt;property&gt;   &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;   &lt;value&gt;false&lt;/value&gt;   &lt;description&gt;     Enforce metastore schema version consistency.     True: Verify that version information stored in is compatible with one from Hive jars.  Also disable automatic           schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures           proper metastore schema migration. (Default)     False: Warn if the version information stored in metastore doesn&#39;t match with one from in Hive jars.   &lt;/description&gt;&lt;/property&gt;&lt;property&gt;   &lt;name&gt;hive.conf.validation&lt;/name&gt;   &lt;value&gt;false&lt;/value&gt;   &lt;description&gt;Enables type checking for registered Hive configurations&lt;/description&gt; &lt;/property&gt;</code></pre><h4 id="删除-description-中的-8，这个解析会报错"><a href="#删除-description-中的-8，这个解析会报错" class="headerlink" title="删除 description 中的 &amp;#8，这个解析会报错"></a>删除 description 中的 <code>&amp;#8</code>，这个解析会报错</h4><pre><code class="xml">&lt;property&gt;   &lt;name&gt;hive.txn.xlock.iow&lt;/name&gt;   &lt;value&gt;true&lt;/value&gt;   &lt;description&gt;     Ensures commands with OVERWRITE (such as INSERT OVERWRITE) acquire Exclusive locks for&amp;#8;transactional tables.  This ensures that inserts (w/o overwrite) running concurrently     are not hidden by the INSERT OVERWRITE.   &lt;/description&gt;&lt;/property&gt;</code></pre><h2 id="Spark任务提交"><a href="#Spark任务提交" class="headerlink" title="Spark任务提交"></a>Spark任务提交</h2><p>打包python依赖，镜像<br>进入到虚拟环境下，如&#x2F;home&#x2F;hadoop&#x2F;anaconda3&#x2F;envs，使用以下命令将虚拟环境进行打包：</p><pre><code class="shell">zip -r conda_env.zip conda_env # 虚拟环境为conda_env, 打包为conda_env.zip 文件</code></pre><h4 id="spark-submit参数设置"><a href="#spark-submit参数设置" class="headerlink" title="spark-submit参数设置"></a>spark-submit参数设置</h4><pre><code class="python">from pyspark.sql import SparkSessionspark_conf = SparkConf().loadPropertiesFile(&quot;spark_config.properties&quot;)spark = SparkSession.builder \    .appName(spark_conf.get(&quot;spark.app.name&quot;)) \    .master(spark_conf.get(&quot;spark.master&quot;)) \    .config(&quot;spark.executor.memory&quot;, spark_conf.get(&quot;spark.executor.memory&quot;)) \    .config(&quot;spark.driver.memory&quot;, spark_conf.get(&quot;spark.driver.memory&quot;)) \    .getOrCreate()# 使用SparkSession进行数据处理和分析</code></pre><pre><code class="bash">$&#123;SPARK_PATH&#125;/bin/spark-submit \ --master yarn \ --name &quot;spark_demo_lr&quot; \ --queue $&#123;YARN_QUEUE&#125; \ --deploy-mode $&#123;DEPLOY_MODE&#125; \ --driver-memory 6g \ --driver-cores 4 \ --executor-memory 12g \ --executor-cores 15 \ --num-executors 10 \ --archives ./source/py27.zip#python_env \ --conf spark.default.parallelism=150 \ --conf spark.executor.memoryOverhead=4g \ --conf spark.driver.memoryOverhead=2g \ --conf spark.yarn.maxAppAttempts=3 \ --conf spark.yarn.submit.waitAppCompletion=true \ --conf spark.pyspark.driver.python=./source/py27/bin/python2 \ --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./python_env/py27/bin/python2 \ --conf spark.pyspark.python=./python_env/py27/bin/python2 \ ./$&#123;ModelType&#125;.py $input_path_train $input_path_test $output_path</code></pre><h4 id="pyspark-传入配置文件参数"><a href="#pyspark-传入配置文件参数" class="headerlink" title="pyspark 传入配置文件参数"></a>pyspark 传入配置文件参数</h4><p>首先，可以使用 <code>--files</code> 参数将配置文件传递给 <code>spark-submit</code> 命令。这将确保配置文件在集群中的每个节点上都可用。以下是一个示例：</p><pre><code class="shell">spark-submit --master yarn --deploy-mode cluster --files /home/sys_user/ask/conf/config.ini test.py</code></pre><p>在 PySpark 脚本中，可以使用 <code>SparkFiles.get()</code> 方法来读取传入的配置文件</p><pre><code class="python">from pyspark import SparkFileswith open(SparkFiles.get(&#39;config.ini&#39;)) as config_file:    print(config_file.read())</code></pre><pre><code class="python">from pyspark.sql import SparkSession# 创建 SparkSessionspark = SparkSession.builder.appName(&quot;ConfigExample&quot;).getOrCreate()# 加载配置参数with open(&quot;config.properties&quot;, &quot;r&quot;) as f:    for line in f:        line = line.strip()        if line and not line.startswith(&quot;#&quot;):            key, value = line.split(&quot;=&quot;)            spark.conf.set(key, value)# 打印配置参数print(&quot;spark.sql.shuffle.partitions:&quot;, spark.conf.get(&quot;spark.sql.shuffle.partitions&quot;))print(&quot;spark.sql.autoBroadcastJoinThreshold:&quot;, spark.conf.get(&quot;spark.sql.autoBroadcastJoinThreshold&quot;))</code></pre><pre><code class="shell">./spark-submit --master yarn --deploy-mode cluster --files /opt/bigdata/config_batch.properties --executor-memory 2g --executor-cores 1 --num-executors 5 --driver-memory 2G  --py-files /usr/local/miniconda3/envs/spark_env.zip --jars /usr/local/spark/jars/mysql-connector-java-5.1.47.jar,/usr/local/spark/jars/taos-jdbcdriver-2.0.34.jar,/usr/local/spark/jars/spark-redis-2.4.0-jar-with-dependencies.jar,/usr/local/spark/jars/fastjson-1.2.73.jar --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=/usr/local/miniconda3/envs/spark_env/bin/python --conf spark.pyspark.python=/usr/local/miniconda3/envs/spark_env/bin/python /opt/bigdata/HealthScoreHFL2.py</code></pre><p>        .master(“local”)<br>        .enableHiveSupport()<br>        .config(‘spark.executor.extraClassPath’, “&#x2F;usr&#x2F;local&#x2F;spark&#x2F;jars&#x2F;mysql-connector-java-5.1.47.jar”)\</p><p>        .config(‘spark.driver.extraClassPath’, “&#x2F;usr&#x2F;local&#x2F;spark&#x2F;jars&#x2F;mysql-connector-java-5.1.47.jar”)\</p><p>        .config(“spark.jars”, “&#x2F;usr&#x2F;local&#x2F;spark&#x2F;jars&#x2F;mysql-connector-java-5.1.47.jar,&#x2F;usr&#x2F;local&#x2F;spark&#x2F;jars&#x2F;taos-jdbcdriver-2.0.34.jar,&#x2F;usr&#x2F;local&#x2F;spark&#x2F;jars&#x2F;spark-redis-2.4.0-jar-with-dependencies.jar,&#x2F;usr&#x2F;local&#x2F;spark&#x2F;jars&#x2F;fastjson-1.2.73.jar”)\</p><pre><code class="shell">./spark-submit --master yarn --deploy-mode cluster --files /opt/bigdata/batch/config_batch.properties --executor-memory 2g --executor-cores 1 --num-executors 5 --driver-memory 2G  --py-files /opt/bigdata/batch/spark3.1_env.zip --jars /usr/local/spark-yarn/jars/mysql-connector-java-5.1.47.jar,/usr/local/spark-yarn/jars/taos-jdbcdriver-2.0.34.jar,/usr/local/spark-yarn/jars/spark-redis-2.4.0-jar-with-dependencies.jar,/usr/local/spark-yarn/jars/fastjson-1.2.73.jar --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=/usr/local/miniconda3/bin/python --conf spark.pyspark.python=/usr/local/miniconda3/bin/python /opt/bigdata/batch/HealthScoreHFL2.py</code></pre>]]></content>
      
      
      <categories>
          
          <category> bigdata </category>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7 CDH&amp;CM 企业内网离线部署</title>
      <link href="/2024/01/08/CentOS%207%20CDH%20&amp;%20CM%20%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/"/>
      <url>/2024/01/08/CentOS%207%20CDH%20&amp;%20CM%20%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="一、CentOS-7-CDH-CM-企业级离线部署"><a href="#一、CentOS-7-CDH-CM-企业级离线部署" class="headerlink" title="一、CentOS 7 CDH &amp; CM 企业级离线部署"></a>一、CentOS 7 CDH &amp; CM 企业级离线部署</h1><p>在文中将有以下提示符对重点进行标注说明，请注意文中提示。</p><p>️ - 文中出现此标记，代表重要提示，指需要格外注意的地方</p><ul><li>-文中出现此标记，代表可选配置，建议配置，但不必要</li></ul><p>✅ - 文中出现此标记，代表检查项目，需要检查对应的配置文件<br>❗️    - 文中出现此标记，代表该操作不可随意修改，如更改此步操作，请预先测试</p><h2 id="Cloudera’s-Distribution-Including-Apache-Hadoop"><a href="#Cloudera’s-Distribution-Including-Apache-Hadoop" class="headerlink" title="Cloudera’s Distribution Including Apache Hadoop"></a>Cloudera’s Distribution Including Apache Hadoop</h2><p>CDH（Cloudera’s Distribution Including Apache Hadoop）是Apache Hadoop和相关项目的最完整，经过测试和最流行的发行版。CDH提供Hadoop的核心要素–可扩展的存储和分布式计算–以及基于Web的用户界面和重要的企业功能。CDH是Apache许可的开源软件，并且是唯一提供统一批处理，交互式SQL和交互式搜索以及基于角色的访问控制的Hadoop解决方案。 一句话概括CDH就是集成多种技术组件的一个框架。</p><p> CDH提供<br>    - 灵活性-存储任何类型的数据并使用各种不同的计算框架进行处理，包括批处理，交互式SQL，自由文本搜索，机器学习和统计计算。<br>    - 集成-在可与广泛的硬件和软件解决方案一起使用的完整Hadoop平台上快速启动并运行。<br>    - 安全性-处理和控制敏感数据。<br>    - 可扩展性-启用广泛的应用程序并进行扩展，并扩展它们以满足您的要求。<br>    - 高可用性-自信地执行关键任务业务任务。<br>    - 兼容性-利用您现有的IT基础架构和投资。</p><p>基于 Web 的用户界面，支持大多数 Hadoop 组件，包括 HDFS、MapReduce、Hive、Pig、Hbase、Zookeeper、Sqoop，简化了大数据平台的安装和使用难度。<br>除此 Apache Hadoop 发行版本之外，还有如下发行版：</p><ul><li>Cloudera’s Distribution Including Apache Hadoop（CDH）「本文使用」</li><li>Hortonworks Data Platform (HDP)</li><li>MapR</li><li>EMR</li></ul><h5 id="Hadoop生态构成"><a href="#Hadoop生态构成" class="headerlink" title="Hadoop生态构成"></a>Hadoop生态构成</h5><ul><li><strong>HDFS:分布式文件系统</strong><ul><li>ZKFC：为实现NameNode高可用，在NameNode和Zookeeper之间传递信息，选举主节点工具。</li><li>NameNode：存储文件元数据</li><li>DateNode：存储具体数据</li><li>JournalNode：同步主NameNode节点数据到从节点NameNode</li></ul></li><li><strong>MapReduce:开源的分布式批处理计算框架</strong></li><li><strong>Spark：分布式基于内存的批处理框架</strong></li><li><strong>Zookeeper:分布式协调管理</strong></li><li><strong>Yarn:调度资源管理器</strong></li><li>HBase：基于HDFS的NoSql列式数据库</li><li><strong>Hive：将SQL转换为MapReduce进行计算</strong></li><li><strong>Hue：是CDH的一个UI框架</strong></li><li><strong>Impala：是Cloudra公司开发的一个查询系统，类似于Hive，可以通过SQL执行任务，但是它不基于MapReduce算法，而是直接执行分布式计算，这样就提高了效率。</strong></li><li>oozie:是一个工作流调度引擎，负责将多个任务组合在一起按序执行。</li><li>kudu：Apache Kudu是转为hadoop平台开发的列式存储管理器。和impala结合使用，可以进行增删改查。</li><li>Sqoop：将hadoop和关系型数据库互相转移的工具。</li><li>Flume：采集日志</li><li>还有一些其它的<br>![[Pasted image 20230702211449.png]]</li></ul><h2 id="Cloudera-Manager"><a href="#Cloudera-Manager" class="headerlink" title="Cloudera Manager"></a>Cloudera Manager</h2><p>Cloudra Manager简称CM，它是一个web操作平台，可以借助安装CDH然后安装多种Hadoop框架。是用于管理 CDH 集群的端到端应用程序，统一管理和安装。CDH 除了可以通过 CM 安装也可以通过 YUM、TAR、RPM 安装。 CloudraManager技术构成：</p><ul><li>Management Server：Cloudera Manager 的核心。主要用于管理 web server 和应用逻辑。它用于安装软件，配置，开始和停止服务，以及管理服务运行的集群。</li><li>API：通过API和ClouderaManagement和服务器进行交互</li><li>agent：分布在多台服务器，它负责启动和停止进程，部署配置，触发安装和监控主机。</li><li>Database：存储配置和监控信息。通常可以在一个或多个数据库服务器上运行的多个逻辑数据库。例如，所述的 Cloudera 管理器服务和监视，后台程序使用不同的逻辑数据库。</li><li>Parcel（Cloudera Repository）：由 Cloudera 提供的软件分发库。</li><li>Clients：客户端，提供了一个与 Server 交互的接口，通过web页面和ClouderaManager和服务器进行交互。<br>结构图如下：<br>![[Pasted image 20230702212900.png]]</li></ul><h2 id="1、部署前准备工作："><a href="#1、部署前准备工作：" class="headerlink" title="1、部署前准备工作："></a>1、部署前准备工作：</h2><h3 id="服务器节点"><a href="#服务器节点" class="headerlink" title="服务器节点"></a>服务器节点</h3><table><thead><tr><th>NAME</th><th>NUMBER</th><th>描述</th></tr></thead><tbody><tr><td>Server</td><td>1</td><td>CM 中 Manager 节点</td></tr><tr><td>Agent</td><td>1+N</td><td>CM 中 其余 Node 节点</td></tr></tbody></table><h3 id="软件包准备"><a href="#软件包准备" class="headerlink" title="软件包准备"></a>软件包准备</h3><p>各服务器节点需要：</p><ul><li>JDK 1.8.0_161「1.8 即可，小版本皆可」</li><li>jdk-8u161-linux-x64.tar.gz<br>Server节点需要安装：</li><li>MySQL 5.7.25</li><li>mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar</li><li>MySQL驱动</li><li>mysql-connector-java-5.1.47.jar</li></ul><p>CDH 安装需准备：</p><ul><li>cm6.3.1-redhat7.tar.gz</li><li>cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm</li><li>cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm</li><li>cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm</li><li>allkeys.asc</li><li>parcel包</li><li>CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel</li><li>CDH-6.3.2-1.cdh6.3.2.p0.1605554-el7.parcel.sha1</li><li>manifest.json</li></ul><h2 id="2、所有节点服务器初始配置"><a href="#2、所有节点服务器初始配置" class="headerlink" title="2、所有节点服务器初始配置"></a>2、所有节点服务器初始配置</h2><ul><li>❗️关闭并禁止开机自启如下服务：系统防火墙（<code>Firewalld</code>、<code>iptables</code>）、<code>NetworkManager</code></li></ul><pre><code class="bash">systemctl stop firewalldsystemctl stop iptablessystemctl stop NetworkManagersystemctl disable firewalldsystemctl disable iptablessystemctl disable NetworkManager</code></pre><ul><li>❗️关闭并禁用 <code>SELinux</code></li></ul><pre><code class="bash">sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/selinux/config</code></pre><ul><li>❗️永久修改各节点的 Hostname 必须防止变回默认</li></ul><pre><code class="bash">hostnamectl set-hostname $HOSTNAME</code></pre><ul><li>❗️添加服务器之间本地域名解析 <code>/etc/hosts</code></li></ul><pre><code class="bash">vi /etc/hosts# incloud itself# 192.168.3.9 PHM01# 192.168.3.10 PHM02# 192.168.3.11 PHM03service network restart</code></pre><ul><li>❗️配置仅使用物理内存，所有主机都需要</li></ul><pre><code class="bash">echo &quot;vm.swappiness=0&quot; &gt;&gt;/etc/sysctl.conf &amp;&amp; sysctl -p</code></pre><ul><li>❗️禁用透明页压缩，所有主机都需要</li></ul><pre><code class="bash">echo &quot;never&quot; &gt;/sys/kernel/mm/transparent_hugepage/defragecho &quot;never&quot; &gt; /sys/kernel/mm/transparent_hugepage/enabledchmod +x /etc/rc.localecho &quot;never&quot; &gt;/sys/kernel/mm/transparent_hugepage/defrag&quot; &gt;&gt;/etc/rc.localecho &quot;never&quot; &gt;/sys/kernel/mm/transparent_hugepage/enabled&quot; &gt;&gt;/etc/rc.localtail ‐2 /sys/kernel/mm/transparent_hugepage/defragtail ‐2 /sys/kernel/mm/transparent_hugepage/enabledtail ‐2 /etc/rc.localif test -f /sys/kernel/mm/transparent_hugepage/enabled; thenecho never &gt; /sys/kernel/mm/transparent_hugepage/enabledfiif test -f /sys/kernel/mm/transparent_hugepage/defrag; thenecho never &gt; /sys/kernel/mm/transparent_hugepage/defragfi# 即时生效 echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled # 永久生效 # /etc/rc.d/rc.local 中增加下列内容 echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled # 赋予rc.local文件执行权限 chmod +x /etc/rc.d/rc.local # 验证 cat /sys/kernel/mm/transparent_hugepage/defrag cat /sys/kernel/mm/transparent_hugepage/enabled</code></pre><ul><li>❗️️ 配置个节点时间同步，确保各个节点时间误差最大不得高于 2s</li></ul><pre><code class="bash">yum -y install ntp</code></pre><p><strong>server</strong></p><pre><code class="bash"># 管理节点使用本地时钟源,执行以下语句即可cat &lt;&lt;EOF&gt;/etc/ntp.confdriftfile /var/lib/ntp/driftrestrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noqueryrestrict 127.0.0.1restrict -6 ::1server 127.127.1.0 iburstincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysEOF</code></pre><p><strong>agent</strong></p><pre><code class="bash"># 其他节点的时钟源为管理节点，执行以下语句即可cat &lt;&lt;EOF&gt;/etc/ntp.confdriftfile /var/lib/ntp/driftrestrict default kod nomodify notrap nopeer noqueryrestrict -6 default kod nomodify notrap nopeer noquery    restrict 127.0.0.1restrict -6 ::1server node1  iburstincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysEOF</code></pre><p>强制设置时间，写入硬件时钟</p><pre><code class="bash"># 修改各节点时间,时间为当前时间date -s &quot;2023-06-30 13:11:07&quot;# 写入硬件时钟hwclock -w</code></pre><p>启动服务，并设置开机自启动</p><pre><code class="bash"># 各节点启动服务systemctl start ntpd &amp;&amp; systemctl enable ntpd</code></pre><ul><li>配置 Java 运行环境，建议安装 JDK 1.8.0_161（亦可选择安装 CDH 时，选择安装 CDH 自带的 Oracle JDK）</li></ul><pre><code class="bash"># JDK 安装路径mkdir -p /usr/local/java</code></pre><p>若操作系统安装有 OpenJDK 则移除系统原有的 JDK</p><pre><code class="bash"># 各节点都需要进行# 查找JDKrpm -aq|grep javarpm -aq|grep jdk# 卸载JDKyum -y remove [上述查找结果的包名]</code></pre><p>安装  JDK 1.8</p><pre><code class="bash"># 在各节点上进行安装# 创建java目录mkdir /usr/java/# 上传jdk目录下jdk-8u162-linux-x64.tar.gz到/usr/java目录 并解压tar -zxvf jdk-8u162-linux-x64.tar.gz -C /usr/java# ️ 修改 jdk 所属用户用户组chown root:root jdk-8u161-linux-x64# 配置环境变量vim ~/.bashrc# 在后面追加下面三行export JAVA_HOME=/usr/java/jdk1.8.0_162export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH# 最后刷新环境变量source ~/.bashrc# 查看 Java 是否安装成功java -version</code></pre><h2 id="3、Server-节点"><a href="#3、Server-节点" class="headerlink" title="3、Server 节点"></a>3、Server 节点</h2><p>若操作系统安装有 mariadb 则手工移除mariadb数据库<br>亦可不移除，在安装 mysql 是会自动处理</p><pre><code class="bash">  rpm -qa | grep mariadb# 结果应为 mariadb-libs-5.5.56-2.el7.x86_64# 卸载  rpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64</code></pre><pre><code class="bash"># 在 server 上安装 mysql 服务# 上传repo目录下mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar安装包到 /home/cdh/ 目录 并解压  tar -xvf mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar# 进入解压目录 安装 mysql  yum install net-tools  rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm mysql-community-client-5.7.25-1.el7.x86_64.rpm mysql-community-common-5.7.25-1.el7.x86_64.rpm mysql-community-libs-5.7.25-1.el7.x86_64.rpm mysql-community-libs-compat-5.7.25-1.el7.x86_64.rpm</code></pre><pre><code class="bash"># 在 server上启动 mysql 服务,并设置自启动  systemctl start mysqld  systemctl enable mysqld</code></pre><pre><code class="bash"># 在node1 上初始化mysql# 获得初始密码  grep &#39;temporary password&#39; /var/log/mysqld.log# 使用初始密码登录  mysql -u root -p# 修改初始密码  # show variables like &#39;validate_password%&#39;;# 查看密码验证策略  set global validate_password_policy=0;# 设置密码验证策略为低  set global validate_password_mixed_case_count=0;# 设置密码至少要包含的大小写字母个数  set global validate_password_number_count=0;# 设置密码至少要包含的数字个数  set global validate_password_special_char_count=0;# 设置密码至少要包含的特殊字符个数  set global validate_password_length=3; # 设置密码最小长度为3  ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;;  grant all privileges on *.* to &#39;root&#39;@&#39;localhost&#39; identified by &#39;123456&#39; with grant option;  grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;123456&#39; with grant option;  flush privileges;  quit;</code></pre><pre><code class="bash"># 在各节点上执行# 上传 repo 目录下 mysql 连接 mysql-connector-java-5.1.47.jar 到 /usr/share/java  ️ mkdir -p /usr/share/java# 重命名  ️ mv mysql-connector-java-5.1.47.jar mysql-connector-java.jar# 授权  ️ chmod 777 mysql-connector-java.jar</code></pre><pre><code class="bash">  yum -y install cloudera-manager-agent cloudera-manager-daemons cloudera-manager-server</code></pre><pre><code class="shell">  ##执行数据库脚本  cd /opt/cloudera/cm/schema  ./scm_prepare_database.sh mysql -uroot -p scm scm scm</code></pre><pre><code class="bash">vi /etc/cloudera-scm-agent/config.iniserver_host=$SERVERHOSTNAME</code></pre><h2 id="4、Agent-节点"><a href="#4、Agent-节点" class="headerlink" title="4、Agent 节点"></a>4、Agent 节点</h2><pre><code class="bash">yum -y install cloudera-manager-agent cloudera-manager-daemo</code></pre><pre><code class="bash">vi /etc/cloudera-scm-agent/config.iniserver_host=$SERVERHOSTNAME</code></pre><h2 id="5、开始启动服务"><a href="#5、开始启动服务" class="headerlink" title="5、开始启动服务"></a>5、开始启动服务</h2><h3 id="server"><a href="#server" class="headerlink" title="server"></a><strong>server</strong></h3><pre><code class="bash">systemctl start cloudera-scm-serversystemctl enable cloudera-scm-serversystemctl start cloudera-scm-agentsystemctl enable cloudera-scm-agent</code></pre><h3 id="agent"><a href="#agent" class="headerlink" title="agent"></a><strong>agent</strong></h3><pre><code class="bash">systemctl start cloudera-scm-agentsystemctl enable cloudera-scm-agent</code></pre><h2 id="6、Web操作"><a href="#6、Web操作" class="headerlink" title="6、Web操作"></a>6、Web操作</h2><p><a href="http://192.168.3.11:7180/">http://192.168.3.11:7180</a><br>默认用户名为 admin<br>默认密码为 admin<br>![[Pasted image 20230705102314.png]]</p><h2 id="附录1-组件建表语句"><a href="#附录1-组件建表语句" class="headerlink" title="附录1 组件建表语句"></a>附录1 组件建表语句</h2><pre><code class="bash">mysql -uroot -p123456  ##给scm授权  grant all privileges on *.* to &#39;scm&#39;@&#39;localhost&#39; identified by &#39;scm&#39; with grant option;  grant all privileges on *.* to &#39;scm&#39;@&#39;%&#39; identified by &#39;scm&#39; with grant option;  ##创建hive数据库  create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;  ##给hive授权  grant all privileges on *.* to &#39;hive&#39;@&#39;localhost&#39; identified by &#39;hive&#39; with grant option;  grant all privileges on *.* to &#39;hive&#39;@&#39;%&#39; identified by &#39;hive&#39; with grant option;  ##创建oozie数据库  create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;  ##给oozie授权  grant all privileges on *.* to &#39;oozie&#39;@&#39;localhost&#39; identified by &#39;oozie&#39; with grant option;  grant all privileges on *.* to &#39;oozie&#39;@&#39;%&#39; identified by &#39;oozie&#39; with grant option;  ##创建hue数据库  create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;  ##给hub授权  grant all privileges on *.* to &#39;hue&#39;@&#39;localhost&#39; identified by &#39;hue&#39; with grant option;  grant all privileges on *.* to &#39;hue&#39;@&#39;%&#39; identified by &#39;hue&#39; with grant option;  ##刷新权限  flush privileges;  ##退出  quit;</code></pre><h2 id="附录2-CDH各组件详细信息"><a href="#附录2-CDH各组件详细信息" class="headerlink" title="附录2 CDH各组件详细信息"></a>附录2 CDH各组件详细信息</h2><table><thead><tr><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>Cloudera Manager Agent</td><td>6.3.1</td><td>所有主机</td><td>1466458.el7</td><td>不适用</td></tr><tr><td>Cloudera Manager Management Daemon</td><td>6.3.1</td><td>所有主机</td><td>1466458.el7</td><td>不适用</td></tr><tr><td>Flume NG</td><td>1.9.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Hadoop</td><td>3.0.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>HDFS</td><td>3.0.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>HttpFS</td><td>3.0.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>hadoop-kms</td><td>3.0.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>MapReduce 2</td><td>3.0.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>YARN</td><td>3.0.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>HBase</td><td>2.1.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Lily HBase Indexer</td><td>1.5+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Hive</td><td>2.1.1+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>HCatalog</td><td>2.1.1+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Hue</td><td>4.2.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Impala</td><td>3.2.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Java 8</td><td>1.8.0_162</td><td>所有主机</td><td>不可用</td><td>不适用</td></tr><tr><td>Kafka</td><td>2.2.1+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Kite（仅限 CDH 5 ）</td><td>1.0.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>kudu</td><td>1.10.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Oozie</td><td>5.1.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Parquet</td><td>1.9.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Pig</td><td>0.17.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>sentry</td><td>2.1.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Solr</td><td>7.4.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>spark</td><td>2.4.0+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>Sqoop</td><td>1.4.7+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr><tr><td>ZooKeeper</td><td>3.4.5+cdh6.3.2</td><td>所有主机</td><td>1605554</td><td>CDH 6</td></tr></tbody></table><h1 id="二、"><a href="#二、" class="headerlink" title="二、"></a>二、</h1>]]></content>
      
      
      <categories>
          
          <category> bigdata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/01/03/hello-world/"/>
      <url>/2024/01/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
